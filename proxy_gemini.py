
# google_proxy.py
import os
from flask import Flask, request, jsonify
import requests
import json

app = Flask(__name__)

TARGET_BASE = "https://runway.devops.rednote.life/openai/google"

# ä»ç¯å¢ƒå˜é‡è¯»å– API Key
API_KEY = os.getenv("GOOGLE_API_KEY", "b243abe1f06f4e24a10cb473c9c49f87")  # ğŸ”´ æ›¿æ¢ä¸ºä½ çš„å®é™… key

def convert_openai_to_google(openai_data):
    """å°† OpenAI æ ¼å¼è½¬æ¢ä¸º Google æ ¼å¼"""
    google_data = {
        "contents": [],
        "generationConfig": {}
    }
    
    # è½¬æ¢ messages
    if "messages" in openai_data:
        for msg in openai_data["messages"]:
            role = msg["role"]
            content = msg["content"]
            
            # å¤„ç† system æ¶ˆæ¯
            if role == "system":
                google_data["systemInstruction"] = {
                    "parts": [{"text": content}]
                }
            # å¤„ç† user å’Œ assistant æ¶ˆæ¯
            else:
                parts = []
                
                # å¤„ç†ä¸åŒç±»å‹çš„ content
                if isinstance(content, str):
                    # ç®€å•æ–‡æœ¬æ¶ˆæ¯
                    parts.append({"text": content})
                elif isinstance(content, list):
                    # å¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆæ–‡æœ¬ + å›¾ç‰‡ï¼‰
                    for item in content:
                        if item.get("type") == "text":
                            parts.append({"text": item["text"]})
                        elif item.get("type") == "image_url":
                            # æå– base64 å›¾ç‰‡æ•°æ®
                            image_url = item["image_url"]["url"]
                            if image_url.startswith("data:"):
                                try:
                                    header, base64_data = image_url.split(",", 1)
                                    mime = header.split(";")[0].split(":")[1]
                                    
                                    parts.append({
                                        "inline_data": {
                                            "mime_type": mime,
                                            "data": base64_data
                                        }
                                    })
                                except Exception as e:
                                    print(f"Error parsing image URL: {e}")
                
                if parts:
                    google_data["contents"].append({
                        "role": "user" if role == "user" else "model",
                        "parts": parts
                    })
    
    # è½¬æ¢ç”Ÿæˆé…ç½®
    if "temperature" in openai_data:
        google_data["generationConfig"]["temperature"] = openai_data["temperature"]
    
    # ğŸ”´ ä½¿ç”¨ OpenAI ä¼ å…¥çš„ max_tokens
    if "max_tokens" in openai_data:
        google_data["generationConfig"]["maxOutputTokens"] = openai_data["max_tokens"]
    else:
        google_data["generationConfig"]["maxOutputTokens"] = 65535
    
    if "top_p" in openai_data:
        google_data["generationConfig"]["topP"] = openai_data["top_p"]
    else:
        google_data["generationConfig"]["topP"] = 1
        
    google_data["generationConfig"]["seed"] = 0
    
    return google_data


def convert_google_to_openai(google_response):
    """å°† Google å“åº”æ ¼å¼è½¬æ¢ä¸º OpenAI æ ¼å¼ï¼ˆæå– thinking å’Œç­”æ¡ˆï¼‰"""
    try:
        text = ""
        thinking = ""
        finish_reason = "stop"
        
        if "candidates" in google_response and len(google_response["candidates"]) > 0:
            candidate = google_response["candidates"][0]
            
            # æå– finish reason
            if "finishReason" in candidate:
                reason = candidate["finishReason"]
                if reason == "MAX_TOKENS":
                    finish_reason = "length"
                    print("âš ï¸  è­¦å‘Šï¼šå“åº”å› è¾¾åˆ° max_tokens é™åˆ¶è¢«æˆªæ–­")
                elif reason == "STOP":
                    finish_reason = "stop"
                else:
                    finish_reason = "stop"
            
            # ğŸ”´ æå–å†…å®¹ï¼ˆå¯èƒ½åŒ…å« thinking å’Œæ™®é€šæ–‡æœ¬ï¼‰
            if "content" in candidate and "parts" in candidate["content"]:
                parts = candidate["content"]["parts"]
                for part in parts:
                    if "text" in part:
                        text += part["text"]
            
            # ğŸ”´ æå– thoughtsï¼ˆå¦‚æœæœ‰å•ç‹¬çš„ thoughts å­—æ®µï¼‰
            if "thoughts" in candidate:
                thinking = "\n".join([t.get("text", "") for t in candidate["thoughts"] if "text" in t])
        
        # ğŸ”´ å¦‚æœæ²¡æœ‰æ–‡æœ¬ä½†æœ‰æ€è€ƒå†…å®¹ï¼Œè®°å½•è­¦å‘Š
        if not text and not thinking:
            print("âŒ è­¦å‘Šï¼šå“åº”ä¸­æ²¡æœ‰æ–‡æœ¬å†…å®¹")
        
        # æ„å»º OpenAI æ ¼å¼å“åº”
        openai_response = {
            "id": "chatcmpl-" + str(hash(text + thinking))[:16],
            "object": "chat.completion",
            "created": 1234567890,
            "model": "google-gemini",
            "choices": [
                {
                    "index": 0,
                    "message": {
                        "role": "assistant",
                        "content": text,
                        "thinking": thinking  # ğŸ”´ æ·»åŠ  thinking å­—æ®µ
                    },
                    "finish_reason": finish_reason
                }
            ],
            "usage": {
                "prompt_tokens": 0,
                "completion_tokens": 0,
                "total_tokens": 0
            }
        }
        
        # æå–ä½¿ç”¨ç»Ÿè®¡
        if "usageMetadata" in google_response:
            metadata = google_response["usageMetadata"]
            thinking_tokens = metadata.get("thoughtsTokenCount", 0)
            
            openai_response["usage"] = {
                "prompt_tokens": metadata.get("promptTokenCount", 0),
                "completion_tokens": metadata.get("candidatesTokenCount", 0),
                "total_tokens": metadata.get("totalTokenCount", 0),
                "thinking_tokens": thinking_tokens  # ğŸ”´ æ·»åŠ æ€è€ƒ token ç»Ÿè®¡
            }
            
            if thinking_tokens > 0:
                print(f"ğŸ’­ æ€è€ƒè¿‡ç¨‹ä½¿ç”¨äº† {thinking_tokens} tokens")
        
        return openai_response
        
    except Exception as e:
        print(f"è½¬æ¢å“åº”æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return {
            "error": {
                "message": f"è½¬æ¢å“åº”å¤±è´¥: {str(e)}",
                "type": "conversion_error"
            }
        }


@app.route('/v1/chat/completions', methods=['POST'])
def chat_completions():
    """å¤„ç† OpenAI æ ¼å¼çš„èŠå¤©è¡¥å…¨è¯·æ±‚"""
    print(f"\n{'='*60}")
    print(f"æ”¶åˆ°è¯·æ±‚: POST /v1/chat/completions")
    
    openai_data = request.get_json()
    request_size = len(json.dumps(openai_data))
    print(f"è¯·æ±‚å¤§å°: {request_size / 1024:.2f} KB")
    print(f"OpenAI è¯·æ±‚æ•°æ®: {json.dumps(openai_data, ensure_ascii=False)[:500]}...")
    
    google_data = convert_openai_to_google(openai_data)
    print(f"Google è¯·æ±‚æ•°æ®: {json.dumps(google_data, ensure_ascii=False)[:500]}...")
    
    url = f"{TARGET_BASE}/v1:generateContent"
    print(f"è½¬å‘åˆ°: {url}")
    
    headers = {
        "api-key": API_KEY,
        "Content-Type": "application/json"
    }
    
    try:
        is_stream = openai_data.get("stream", False)
        
        if is_stream:
            return jsonify({"error": "Stream mode not supported yet"}), 400
        
        # å‘é€è¯·æ±‚
        import time
        start_time = time.time()
        print("â³ æ­£åœ¨ç­‰å¾… API å“åº”...")
        
        resp = requests.post(
            url=url,
            headers=headers,
            json=google_data,
            timeout=300  # ğŸ”´ 5åˆ†é’Ÿè¶…æ—¶
        )
        
        elapsed = time.time() - start_time
        print(f"âœ… å“åº”æ¥æ”¶å®Œæˆ (è€—æ—¶: {elapsed:.2f}s)")
        print(f"å“åº”çŠ¶æ€ç : {resp.status_code}")
        
        if resp.status_code == 200:
            google_response = resp.json()
            print(f"Google å“åº”: {json.dumps(google_response, ensure_ascii=False)[:500]}...")
            
            openai_response = convert_google_to_openai(google_response)
            print(f"OpenAI å“åº”: {json.dumps(openai_response, ensure_ascii=False)[:500]}...")
            
            return jsonify(openai_response), 200
        else:
            error_text = resp.text
            print(f"é”™è¯¯å“åº”: {error_text}")
            return jsonify({
                "error": {
                    "message": error_text,
                    "type": "api_error",
                    "code": resp.status_code
                }
            }), resp.status_code
            
    except requests.exceptions.Timeout:
        print(f"âŒ è¯·æ±‚è¶…æ—¶ (è¶…è¿‡ 300 ç§’)")
        return jsonify({
            "error": {
                "message": "Request timeout after 300 seconds",
                "type": "timeout"
            }
        }), 504
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "error": {
                "message": str(e),
                "type": "internal_error"
            }
        }), 500


@app.route('/v1/models', methods=['GET'])
def list_models():
    """è¿”å›å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    return jsonify({
        "object": "list",
        "data": [
            {
                "id": "google-gemini",
                "object": "model",
                "created": 1234567890,
                "owned_by": "google"
            }
        ]
    })


if __name__ == '__main__':
    print("=" * 60)
    print("ğŸš€ Google Gemini to OpenAI ä»£ç†æœåŠ¡å™¨å¯åŠ¨")
    print("=" * 60)
    print(f"API Key çŠ¶æ€: {'âœ… å·²è®¾ç½®' if API_KEY and API_KEY != 'your_actual_api_key_here' else 'âŒ æœªè®¾ç½®'}")
    print("ç›‘å¬åœ°å€: http://localhost:8008/v1")
    print("\nåŠŸèƒ½ç‰¹æ€§:")
    print("  âœ… æ”¯æŒæå– thinking å†…å®¹")
    print("  âœ… æ”¯æŒå¤§ token é™åˆ¶ (æœ€é«˜ 65535)")
    print("  âœ… 5åˆ†é’Ÿè¶…æ—¶è®¾ç½®")
    print("=" * 60)
    
    app.run(host='0.0.0.0', port=8008, debug=True, use_reloader=False, threaded=True)
